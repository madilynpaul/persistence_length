{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbb1ac92-fb6f-4e26-92ac-cdb740179ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import MDAnalysis as mda\n",
    "from MDAnalysis.analysis import polymer\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "def autocorr1D(array):\n",
    "    \"\"\"Takes in a linear np array, performs autocorrelation\n",
    "    function and returns normalized array with half the length\n",
    "    of the input.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy.typing.Arraylike, required\n",
    "        1-D series of data to perform autocorrelation on.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    1D np.array\n",
    "\n",
    "    \"\"\"\n",
    "    ft = np.fft.rfft(array - np.average(array))\n",
    "    acorr = np.fft.irfft(ft * np.conjugate(ft)) / (len(array) * np.var(array))\n",
    "    return acorr[0 : len(acorr) // 2]  # noqa: E203\n",
    "\n",
    "def persistence_length(filepath,start,stop,interval):\n",
    "    \"\"\"\n",
    "    filepath needs to be a format in which you can\n",
    "    create an mdanalysis universe from, we mostly use gsd files\n",
    "    \"\"\"\n",
    "    u = mda.Universe(topology=filepath)\n",
    "\n",
    "    \"\"\"rewrite atom indices\"\"\"\n",
    "    bond_indices = []\n",
    "    particle_index = [0]\n",
    "    for i in range(len(u.bonds)):\n",
    "        a = u.bonds[i].atoms.indices\n",
    "        bond_indices.append(list(a))\n",
    "        if particle_index[-1] in bond_indices[i]:\n",
    "            atom1 = bond_indices[i][0]\n",
    "            atom2 = bond_indices[i][1]\n",
    "            if atom1 not in particle_index:\n",
    "                particle_index.append(atom1)\n",
    "            if atom2 not in particle_index:\n",
    "                particle_index.append(atom2)\n",
    "\n",
    "    \"\"\"create bonds list\"\"\"\n",
    "    av = []\n",
    "    bond_len = []\n",
    "    for t in u.trajectory[start:stop:interval]:\n",
    "        particle_positions = []\n",
    "        bonds = []\n",
    "        unit_bonds = []\n",
    "        bond_lengths = []\n",
    "        angles = []\n",
    "\n",
    "        for i in particle_index:\n",
    "            pos = t.positions[i]\n",
    "            particle_positions.append(pos)\n",
    "        for i in range(len(u.bonds)):\n",
    "            b = particle_positions[i+1]-particle_positions[i]\n",
    "            bonds.append(b)\n",
    "            l2 = t.dimensions[0]/2\n",
    "            for i,b in enumerate(bonds):\n",
    "                for j,x in enumerate(b):\n",
    "                    if x>l2:\n",
    "                        bonds[i][j] = x-l2*2\n",
    "                    if x<-l2:\n",
    "                        bonds[i][j] = x+l2*2\n",
    "            a = b/np.linalg.norm(b)\n",
    "            unit_bonds.append(a)\n",
    "            length = np.linalg.norm(b)\n",
    "            bond_lengths.append(length)\n",
    "            #l_b = np.mean(bond_lengths)\n",
    "        bond_len.append(bond_lengths)\n",
    "\n",
    "        for i in range(len(unit_bonds)-1):\n",
    "            b1 = unit_bonds[0]\n",
    "            b2 = unit_bonds[0+i]\n",
    "            dot_product = np.dot(b1,b2)\n",
    "            angles.append(dot_product)\n",
    "\n",
    "        n=len(u.atoms)\n",
    "        n_frames = 1\n",
    "        n_chains = 1\n",
    "        norm = np.linspace(n - 1, 1, n - 1)\n",
    "        norm *= n_chains * n_frames\n",
    "        auto = autocorr1D(angles)\n",
    "        av.append(auto)\n",
    "\n",
    "    '''average the data from trajectories together'''\n",
    "    sums = []\n",
    "    for j in range(len(av[0])):\n",
    "        k = []\n",
    "        for i in range(len(av)):\n",
    "            a = av[i][j]\n",
    "            k.append(a)\n",
    "        sum = np.sum(k)\n",
    "        sums.append(sum)\n",
    "    l_b = np.average(bond_len)\n",
    "    result = [x/len(av) for x in sums]\n",
    "    x = [i for i in range(len(sums))]\n",
    "\n",
    "    '''set negative results to 0'''\n",
    "    for r in range(len(result)):\n",
    "        if result[r] < 0:\n",
    "            result[r] = 0\n",
    "    def expfunc(x, a):\n",
    "        return np.exp(-x/a)\n",
    "\n",
    "    exp_coeff = scipy.optimize.curve_fit(expfunc,x,result)[0][0]\n",
    "\n",
    "    l_p = exp_coeff * l_b\n",
    "\n",
    "    fit = np.exp(-(x/exp_coeff))\n",
    "\n",
    "    return l_p, l_b, x, result, fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a4a52d-357e-42a6-b7a1-5ded9188aa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook lp_nb.ipynb to latex\n",
      "[NbConvertApp] Writing 30173 bytes to lp_nb.tex\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to latex lp_nb.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8717cca9-dbc4-4654-bc66-20bda349efac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
